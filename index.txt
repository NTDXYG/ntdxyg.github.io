1:"$Sreact.fragment"
2:I[3719,["17","static/chunks/17-9c04c9413a9f9f1f.js","874","static/chunks/874-6cc630662f3664af.js","862","static/chunks/862-15038af301665bb3.js","177","static/chunks/app/layout-41db43831ab81c7f.js"],"ThemeProvider"]
3:I[768,["17","static/chunks/17-9c04c9413a9f9f1f.js","874","static/chunks/874-6cc630662f3664af.js","862","static/chunks/862-15038af301665bb3.js","177","static/chunks/app/layout-41db43831ab81c7f.js"],"default"]
4:I[7555,[],""]
5:I[1295,[],""]
6:I[2548,["17","static/chunks/17-9c04c9413a9f9f1f.js","874","static/chunks/874-6cc630662f3664af.js","862","static/chunks/862-15038af301665bb3.js","177","static/chunks/app/layout-41db43831ab81c7f.js"],"default"]
7:I[8548,["17","static/chunks/17-9c04c9413a9f9f1f.js","82","static/chunks/82-0a710f0d74b82ba6.js","874","static/chunks/874-6cc630662f3664af.js","748","static/chunks/748-55ca435efe938ca9.js","974","static/chunks/app/page-b21f3647966a377f.js"],"default"]
8:I[9507,["17","static/chunks/17-9c04c9413a9f9f1f.js","82","static/chunks/82-0a710f0d74b82ba6.js","874","static/chunks/874-6cc630662f3664af.js","748","static/chunks/748-55ca435efe938ca9.js","974","static/chunks/app/page-b21f3647966a377f.js"],"default"]
9:I[5218,["17","static/chunks/17-9c04c9413a9f9f1f.js","82","static/chunks/82-0a710f0d74b82ba6.js","874","static/chunks/874-6cc630662f3664af.js","748","static/chunks/748-55ca435efe938ca9.js","974","static/chunks/app/page-b21f3647966a377f.js"],"default"]
14:I[1990,["17","static/chunks/17-9c04c9413a9f9f1f.js","82","static/chunks/82-0a710f0d74b82ba6.js","874","static/chunks/874-6cc630662f3664af.js","748","static/chunks/748-55ca435efe938ca9.js","974","static/chunks/app/page-b21f3647966a377f.js"],"default"]
15:I[9665,[],"MetadataBoundary"]
17:I[9665,[],"OutletBoundary"]
1a:I[4911,[],"AsyncMetadataOutlet"]
1c:I[9665,[],"ViewportBoundary"]
1e:I[6614,[],""]
:HL["/_next/static/css/83a1ddabe21917ec.css","style"]
a:T736,Trustworthy evaluation methods for code snippets play a crucial role in neural code generation. Traditional methods, which either rely on reference solutions or require executable test cases, have inherent limitation in flexibility and scalability. The recent LLM-as-Judge methodology offers a promising alternative by directly evaluating functional consistency between the problem description and the generated code. To systematically understand the landscape of these LLM-as-Judge methods, we conduct a comprehensive empirical study across three diverse datasets. Our investigation reveals the pros and cons of two categories of LLM-as-Judge methods: the methods based on general foundation models can achieve good performance but require complex prompts and lack explainability, while the methods based on reasoning foundation models provide better explainability with simpler prompts but demand substantial computational resources due to their large parameter sizes. To address these limitations, we propose CODE-DITING, a novel code evaluation method that balances accuracy, efficiency and explainability. We develop a data distillation framework that effectively transfers reasoning capabilities from DeepSeek-R1671B to our CODE-DITING 1.5B and 7B models, significantly enhancing evaluation explainability and reducing the computational cost. With the majority vote strategy in the inference process, CODE-DITING 1.5B outperforms all models with the same magnitude of parameters and achieves performance which would normally exhibit in a model with 5 times of parameter scale. CODE-DITING 7B surpasses GPT-4o and DeepSeek-V3 671B, even though it only uses 1% of the parameter volume of these large models. Further experiments show that CODEDITING is robust to preference leakage and can serve as a promising alternative for code evaluation.b:T903,@inproceedings{yang2025codediting,
  title = {Code-DiTing: Automatic Evaluation of Code Generation without References or Test Cases},
  abbr = {ASE'25},
  author = {Yang, Guang and Zhou, Yu and Chen, Xiang and Zheng, Wei and Hu, Xing and Zhou, Xin and Lo, David and Chen, Taolue},
  tags = {CCF-A;EI},
  booktitle = {Proceedings of the 40th IEEE/ACM International Conference on Automated Software Engineering},
  year = {2025},
  month = {11},
  abstract = {Trustworthy evaluation methods for code snippets play a crucial role in neural code generation. Traditional methods, which either rely on reference solutions or require executable test cases, have inherent limitation in flexibility and scalability. The recent LLM-as-Judge methodology offers a promising alternative by directly evaluating functional consistency between the problem description and the generated code. To systematically understand the landscape of these LLM-as-Judge methods, we conduct a comprehensive empirical study across three diverse datasets. Our investigation reveals the pros and cons of two categories of LLM-as-Judge methods: the methods based on general foundation models can achieve good performance but require complex prompts and lack explainability, while the methods based on reasoning foundation models provide better explainability with simpler prompts but demand substantial computational resources due to their large parameter sizes. To address these limitations, we propose CODE-DITING, a novel code evaluation method that balances accuracy, efficiency and explainability. We develop a data distillation framework that effectively transfers reasoning capabilities from DeepSeek-R1671B to our CODE-DITING 1.5B and 7B models, significantly enhancing evaluation explainability and reducing the computational cost. With the majority vote strategy in the inference process, CODE-DITING 1.5B outperforms all models with the same magnitude of parameters and achieves performance which would normally exhibit in a model with 5 times of parameter scale. CODE-DITING 7B surpasses GPT-4o and DeepSeek-V3 671B, even though it only uses 1% of the parameter volume of these large models. Further experiments show that CODEDITING is robust to preference leakage and can serve as a promising alternative for code evaluation.}
}c:T55a,The widespread use of Large Language Models (LLMs) in software engineering has intensified the need for improved model and resource efficiency. In particular, for neural code generation, LLMs are used to translate function/method signature and DocString to executable code. DocStrings, which capture user requirements for the code and are typically used as the prompt for LLMs, often contain redundant information. Recent advancements in prompt compression have shown promising results in Natural Language Processing (NLP), but their applicability to code generation remains uncertain. Our empirical study show that the state-of-the-art prompt compression methods achieve only about 10% reduction, as further reductions would cause significant performance degradation. In our study, we propose a novel compression method, ShortenDoc, dedicated to DocString compression for code generation. Our experiments on six code generation datasets, five open-source LLMs (1B to 10B parameters) and one closed-source LLM GPT-4o confirm that ShortenDoc achieves 25‚Äì40% compression while preserving the quality of generated code, outperforming other baseline methods at similar compression levels. The benefit of this method is to improve efficiency and reduce the token processing cost while maintaining the quality of the generated code, especially when calling third-party APIs.d:T7a9,@article{10.1145/3735636,
  author = {Yang, Guang and Zhou, Yu and Cheng, Wei and Zhang, Xiangyu and Chen, Xiang and Zhuo, Terry Yue and Liu, Ke and Zhou, Xin and Lo, David and Chen, Taolue},
  abbr = {TOSEM'25},
  tags = {SCI-Q1; CCF-A},
  title = {Less is More: DocString Compression in Code Generation},
  year = {2025},
  month = {5},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  issn = {1049-331X},
  doi = {10.1145/3735636},
  abstract = {The widespread use of Large Language Models (LLMs) in software engineering has intensified the need for improved model and resource efficiency. In particular, for neural code generation, LLMs are used to translate function/method signature and DocString to executable code. DocStrings, which capture user requirements for the code and are typically used as the prompt for LLMs, often contain redundant information. Recent advancements in prompt compression have shown promising results in Natural Language Processing (NLP), but their applicability to code generation remains uncertain. Our empirical study show that the state-of-the-art prompt compression methods achieve only about 10\% reduction, as further reductions would cause significant performance degradation. In our study, we propose a novel compression method, ShortenDoc, dedicated to DocString compression for code generation. Our experiments on six code generation datasets, five open-source LLMs (1B to 10B parameters) and one closed-source LLM GPT-4o confirm that ShortenDoc achieves 25‚Äì40\% compression while preserving the quality of generated code, outperforming other baseline methods at similar compression levels. The benefit of this method is to improve efficiency and reduce the token processing cost while maintaining the quality of the generated code, especially when calling third-party APIs.},
  note = {Just Accepted},
  journal = {ACM Transactions on Software Engineering and Methodology}
}e:T856,Code Language Models (CLMs), particularly those leveraging deep learning, have achieved significant success in code intelligence domain. However, the issue of security, particularly backdoor attacks, is often overlooked in this process. The previous research has focused on designing backdoor attacks for CLMs, but effective defenses have not been adequately addressed. In particular, existing defense methods from natural language processing, when directly applied to CLMs, are not effective enough and lack generality, working well in some models and scenarios but failing in others, thus fall short in consistently mitigating backdoor attacks. To bridge this gap, we first confirm the phenomenon of ‚Äúearly learning‚Äù as a general occurrence during the training of CLMs. This phenomenon refers to that a model initially focuses on the main features of training data but may become more sensitive to backdoor triggers over time, leading to overfitting and susceptibility to backdoor attacks. We then analyze that overfitting to backdoor triggers results from the use of the cross-entropy loss function, where the unboundedness of cross-entropy leads the model to increasingly concentrate on the features of the poisoned data. Based on this insight, we propose a general and effective loss function DeCE (Deceptive Cross-Entropy) by blending deceptive distributions and applying label smoothing to limit the gradient to bounded, which prevents the model from overfitting to backdoor triggers and then enhances the security of CLMs against backdoor attacks. To evaluate the effectiveness of our defense method, we select four code-related tasks as our experiments scenes and conduct experimental analyses on both natural language and two programming languages (Java and Python). Our experiments across multiple models with different sizes (from 125M to 7B) and poisoning ratios demonstrate the applicability and effectiveness of DeCE in enhancing the security of CLMs. The findings emphasize the potential of DeCE as a novel defense mechanism for CLMs, effectively tackling the challenge of securing models against backdoor threats.f:Tac4,@article{10.1145/3728639,
  author = {Yang, Guang and Zhou, Yu and Zhang, Xiangyu and Chen, Xiang and Zhuo, Terry and Lo, David and Chen, Taolue},
  abbr = {TOSEM'25},
  tags = {SCI-Q1; CCF-A},
  title = {Defending Code Language Models against Backdoor Attacks with Deceptive Cross-Entropy Loss},
  year = {2025},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  issn = {1049-331X},
  url = {https://doi.org/10.1145/3728639},
  doi = {10.1145/3728639},
  abstract = {Code Language Models (CLMs), particularly those leveraging deep learning, have achieved significant success in code intelligence domain. However, the issue of security, particularly backdoor attacks, is often overlooked in this process. The previous research has focused on designing backdoor attacks for CLMs, but effective defenses have not been adequately addressed. In particular, existing defense methods from natural language processing, when directly applied to CLMs, are not effective enough and lack generality, working well in some models and scenarios but failing in others, thus fall short in consistently mitigating backdoor attacks. To bridge this gap, we first confirm the phenomenon of ‚Äúearly learning‚Äù as a general occurrence during the training of CLMs. This phenomenon refers to that a model initially focuses on the main features of training data but may become more sensitive to backdoor triggers over time, leading to overfitting and susceptibility to backdoor attacks. We then analyze that overfitting to backdoor triggers results from the use of the cross-entropy loss function, where the unboundedness of cross-entropy leads the model to increasingly concentrate on the features of the poisoned data. Based on this insight, we propose a general and effective loss function DeCE (Deceptive Cross-Entropy) by blending deceptive distributions and applying label smoothing to limit the gradient to bounded, which prevents the model from overfitting to backdoor triggers and then enhances the security of CLMs against backdoor attacks. To evaluate the effectiveness of our defense method, we select four code-related tasks as our experiments scenes and conduct experimental analyses on both natural language and two programming languages (Java and Python). Our experiments across multiple models with different sizes (from 125M to 7B) and poisoning ratios demonstrate the applicability and effectiveness of DeCE in enhancing the security of CLMs. The findings emphasize the potential of DeCE as a novel defense mechanism for CLMs, effectively tackling the challenge of securing models against backdoor threats.},
  note = {Just Accepted},
  journal = {ACM Transactions on Software Engineering and Methodology},
  month = {5}
}10:T5cb,Large Language Models (LLMs) have demonstrated remarkable potential in code generation. The integration of Chain of Thought (CoT) reasoning can further boost their performance. However, current CoT methods often require manual writing or LLMs with over 100 billion parameters to generate, impeding their applicability in resource-constrained scenarios. In this study, we investigate lightweight Language Models ( ‚ÑìLMs), which are defined to have fewer than 10 billion parameters. Empirically, we find that most ‚ÑìLMs cannot generate high-quality CoTs when prompted by the few-shot method, but can take advantage of high-quality CoTs generated elsewhere to improve their performance in code generation. Based on these findings, we design a novel approach COTTON which can leverage ‚ÑìLMs to automatically generate CoTs for code generation. We synthesize new datasets and conduct extensive experiments on various benchmarks. The results show that the CoTs generated by COTTON outperform the baselines in terms of automated and human evaluation metrics. In particular, the CoTs generated by COTTON boost various ‚ÑìLMs to achieve higher performance gains than those generated by LLMs such as ChatGLM (130B), and are competitive with those generated by Gemini and gpt-3.5-turbo. The results also reveal that COTTON not only improves the performance of ‚ÑìLMs, but also enhances the performance of LLMs. Our study showcases the potential of ‚ÑìLMs in software engineering applications.11:T7a3,@ARTICLE{10634302,
  author = {Yang, Guang and Zhou, Yu and Chen, Xiang and Zhang, Xiangyu and Zhuo, Terry Yue and Chen, Taolue},
  abbr = {TSE'24},
  tags = {SCI-Q1; CCF-A},
  journal = {IEEE Transactions on Software Engineering},
  title = {Chain-of-Thought in Neural Code Generation: From and for Lightweight Language Models},
  year = {2024},
  month = {12},
  volume = {50},
  number = {9},
  pages = {2437-2457},
  doi = {10.1109/TSE.2024.3440503},
  abstract = {Large Language Models (LLMs) have demonstrated remarkable potential in code generation. The integration of Chain of Thought (CoT) reasoning can further boost their performance. However, current CoT methods often require manual writing or LLMs with over 100 billion parameters to generate, impeding their applicability in resource-constrained scenarios. In this study, we investigate lightweight Language Models ( ‚ÑìLMs), which are defined to have fewer than 10 billion parameters. Empirically, we find that most ‚ÑìLMs cannot generate high-quality CoTs when prompted by the few-shot method, but can take advantage of high-quality CoTs generated elsewhere to improve their performance in code generation. Based on these findings, we design a novel approach COTTON which can leverage ‚ÑìLMs to automatically generate CoTs for code generation. We synthesize new datasets and conduct extensive experiments on various benchmarks. The results show that the CoTs generated by COTTON outperform the baselines in terms of automated and human evaluation metrics. In particular, the CoTs generated by COTTON boost various ‚ÑìLMs to achieve higher performance gains than those generated by LLMs such as ChatGLM (130B), and are competitive with those generated by Gemini and gpt-3.5-turbo. The results also reveal that COTTON not only improves the performance of ‚ÑìLMs, but also enhances the performance of LLMs. Our study showcases the potential of ‚ÑìLMs in software engineering applications.}
}12:T695,Pre-trained code generation models (PCGMs) have been widely applied in neural code generation, which can generate executable code from functional descriptions in natural languages, possibly together with signatures. Despite substantial performance improvement of PCGMs, the role of method names in neural code generation has not been thoroughly investigated. In this article, we study and demonstrate the potential of benefiting from method names to enhance the performance of PCGMs from a model robustness perspective. Specifically, we propose a novel approach, named neuRAl coDe generAtor Robustifier (RADAR). RADAR consists of two components: RADAR-Attack and RADAR-Defense. The former attacks a PCGM by generating adversarial method names as part of the input, which are semantic and visual similar to the original input but may trick the PCGM to generate completely unrelated code snippets. As a countermeasure to such attacks, RADAR-Defense synthesizes a new method name from the functional description and supplies it to the PCGM. Evaluation results show that RADAR-Attack can reduce the CodeBLEU of generated code by 19.72% to 38.74% in three state-of-the-art PCGMs (i.e., CodeGPT, PLBART, and CodeT5) in the fine-tuning code generation task and reduce the Pass@1 of generated code by 32.28% to 44.42% in three state-of-the-art PCGMs (i.e., Replit, CodeGen, and CodeT5+) in the zero-shot code generation task. Moreover, RADAR-Defense is able to reinstate the performance of PCGMs with synthesized method names. These results highlight the importance of good method names in neural code generation and implicate the benefits of studying model robustness in software engineering.13:T8a0,@article{yang2024important,
  title = {How important are good method names in neural code generation? a model robustness perspective},
  abbr = {TOSEM'24},
  tags = {SCI-Q1; CCF-A},
  month = {3},
  author = {Yang, Guang and Zhou, Yu and Yang, Wenhua and Yue, Tao and Chen, Xiang and Chen, Taolue},
  journal = {ACM Transactions on Software Engineering and Methodology},
  volume = {33},
  number = {3},
  pages = {1--35},
  year = {2024},
  publisher = {ACM New York, NY, USA},
  doi = {10.1145/3630010},
  abstract = {Pre-trained code generation models (PCGMs) have been widely applied in neural code generation, which can generate executable code from functional descriptions in natural languages, possibly together with signatures. Despite substantial performance improvement of PCGMs, the role of method names in neural code generation has not been thoroughly investigated. In this article, we study and demonstrate the potential of benefiting from method names to enhance the performance of PCGMs from a model robustness perspective. Specifically, we propose a novel approach, named neuRAl coDe generAtor Robustifier (RADAR). RADAR consists of two components: RADAR-Attack and RADAR-Defense. The former attacks a PCGM by generating adversarial method names as part of the input, which are semantic and visual similar to the original input but may trick the PCGM to generate completely unrelated code snippets. As a countermeasure to such attacks, RADAR-Defense synthesizes a new method name from the functional description and supplies it to the PCGM. Evaluation results show that RADAR-Attack can reduce the CodeBLEU of generated code by 19.72% to 38.74% in three state-of-the-art PCGMs (i.e., CodeGPT, PLBART, and CodeT5) in the fine-tuning code generation task and reduce the Pass@1 of generated code by 32.28% to 44.42% in three state-of-the-art PCGMs (i.e., Replit, CodeGen, and CodeT5+) in the zero-shot code generation task. Moreover, RADAR-Defense is able to reinstate the performance of PCGMs with synthesized method names. These results highlight the importance of good method names in neural code generation and implicate the benefits of studying model robustness in software engineering.}
}0:{"P":null,"b":"Zct0ahGRq55EOjDMobfvn","p":"","c":["",""],"i":false,"f":[[["",{"children":["__PAGE__",{}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/83a1ddabe21917ec.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","className":"scroll-smooth","suppressHydrationWarning":true,"children":[["$","head",null,{"children":[["$","link",null,{"rel":"icon","href":"/favicon.png","type":"image/svg+xml"}],["$","link",null,{"rel":"dns-prefetch","href":"https://google-fonts.jialeliu.com"}],["$","link",null,{"rel":"preconnect","href":"https://google-fonts.jialeliu.com","crossOrigin":""}],["$","link",null,{"rel":"preload","as":"style","href":"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap"}],["$","link",null,{"rel":"stylesheet","id":"gfonts-css","href":"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap","media":"print"}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              (function(){\n                var l = document.getElementById('gfonts-css');\n                if (!l) return;\n                if (l.media !== 'all') {\n                  l.addEventListener('load', function(){ try { l.media = 'all'; } catch(e){} });\n                }\n              })();\n            "}}],["$","noscript",null,{"children":["$","link",null,{"rel":"stylesheet","href":"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap"}]}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              try {\n                const theme = localStorage.getItem('theme-storage');\n                const parsed = theme ? JSON.parse(theme) : null;\n                const setting = parsed?.state?.theme || 'system';\n                const prefersDark = typeof window !== 'undefined' && window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;\n                const effective = setting === 'dark' ? 'dark' : (setting === 'light' ? 'light' : (prefersDark ? 'dark' : 'light'));\n                var root = document.documentElement;\n                root.classList.add(effective);\n                root.setAttribute('data-theme', effective);\n              } catch (e) {\n                var root = document.documentElement;\n                root.classList.add('light');\n                root.setAttribute('data-theme', 'light');\n              }\n            "}}]]}],["$","body",null,{"className":"font-sans antialiased","children":["$","$L2",null,{"children":[["$","$L3",null,{"items":[{"title":"About","type":"page","target":"about","href":"/"},{"title":"Publications","type":"page","target":"publications","href":"/publications"},{"title":"Awards","type":"page","target":"awards","href":"/awards"},{"title":"Services","type":"page","target":"services","href":"/services"}],"siteTitle":"Guang Yang","enableOnePageMode":false}],["$","main",null,{"className":"min-h-screen pt-16 lg:pt-20","children":["$","$L4",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}],["$","$L6",null,{"lastUpdated":"November 18, 2025"}]]}]}]]}]]}],{"children":["__PAGE__",["$","$1","c",{"children":[["$","div",null,{"className":"max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-8 bg-background min-h-screen","children":["$","div",null,{"className":"grid grid-cols-1 lg:grid-cols-3 gap-12","children":[["$","div",null,{"className":"lg:col-span-1","children":["$","$L7",null,{"author":{"name":"Guang Yang","title":"Postdoctoral Researcher","institution":"Zhejiang University","avatar":"/yg.jpg"},"social":{"email":"novelyg@outlook.com","google_scholar":"https://scholar.google.com/citations?user=JFoOXQwAAAAJ&hl=zh-CN","orcid":"https://orcid.org/my-orcid?orcid=0000-0002-3374-6680","github":"https://github.com/NTDXYG","cv":"/main.pdf"},"features":{"enable_likes":true,"enable_one_page_mode":false},"researchInterests":["Code Generation","Artificial Intelligence for Software Engineering"]}]}],["$","div",null,{"className":"lg:col-span-2 space-y-8","children":[["$","section","about",{"id":"about","className":"scroll-mt-24 space-y-8","children":[[["$","$L8","about",{"content":"I am currently a Postdoctoral Researcher at Zhejiang University, working with [Prof. Xin Xia](https://xin-xia.github.io/) and [Prof. Xing Hu](https://xing-hu.github.io/).\r\n\r\nPrior to this, I received my B.Sc. and M.Sc. degrees from Nantong University, supervised by [Prof. Xiang Chen](https://smartse.github.io/). \r\nI obtained my Ph.D. degree from Nanjing University of Aeronautics and Astronautics, supervised by [Prof. Yu Zhou](https://csyuzhou.github.io/) and [Prof. Taolue Chen](https://chentaolue.github.io/). \r\nFrom August 2024 to July 2025, I was a visiting scholar at Singapore Management University, advised by [Prof. David Lo](http://www.mysmu.edu/faculty/davidlo/).\r\n\r\nMy current research focuses on Code Generation, a trending intersection of Artificial Intelligence and Software Engineering. I have published about 40 papers in total, including 5 first-authored CCF-A papers. \r\n\r\nI am open to research discussions and collaborations. Please feel free to contact me.","title":"About"}],["$","$L9","featured_publications",{"publications":[{"id":"yang2025codediting","title":"Code-DiTing: Automatic Evaluation of Code Generation without References or Test Cases","abbr":"ASE'25","authors":[{"name":"Guang Yang","isHighlighted":true,"isCorresponding":false,"isCoAuthor":false},{"name":"Yu Zhou","isHighlighted":false,"isCorresponding":true,"isCoAuthor":false},{"name":"Xiang Chen","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Wei Zheng","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Xing Hu","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Xin Zhou","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"David Lo","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Taolue Chen","isHighlighted":false,"isCorresponding":true,"isCoAuthor":false}],"year":2025,"month":"11","type":"conference","status":"published","tags":["CCF-A","EI"],"keywords":[],"researchArea":"machine-learning","journal":"","conference":"Proceedings of the 40th IEEE/ACM International Conference on Automated Software Engineering","code":"https://github.com/CODE-DITING/CODE-DITING","abstract":"$a","description":"A novel LLM-as-Judge method for code evaluation, balancing accuracy, efficiency and explainability.","selected":true,"bibtex":"$b"},{"id":"10.1145/3735636","title":"Less is More: DocString Compression in Code Generation","abbr":"TOSEM'25","authors":[{"name":"Guang Yang","isHighlighted":true,"isCorresponding":false,"isCoAuthor":false},{"name":"Yu Zhou","isHighlighted":false,"isCorresponding":true,"isCoAuthor":false},{"name":"Wei Cheng","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Xiangyu Zhang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Xiang Chen","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Terry Yue Zhuo","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Ke Liu","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Xin Zhou","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"David Lo","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Taolue Chen","isHighlighted":false,"isCorresponding":true,"isCoAuthor":false}],"year":2025,"month":"5","type":"journal","status":"published","tags":["SCI-Q1","CCF-A"],"keywords":["DocString Compression","Code Generation","Large Language Model"],"researchArea":"machine-learning","journal":"ACM Transactions on Software Engineering and Methodology","conference":"","doi":"10.1145/3735636","code":"https://github.com/NTDXYG/ShortenDoc","abstract":"$c","description":"A novel DocString compression method for code generation, achieving significant reduction in token processing cost while preserving the quality of the generated code.","selected":true,"bibtex":"$d"},{"id":"10.1145/3728639","title":"Defending Code Language Models against Backdoor Attacks with Deceptive Cross-Entropy Loss","abbr":"TOSEM'25","authors":[{"name":"Guang Yang","isHighlighted":true,"isCorresponding":false,"isCoAuthor":false},{"name":"Yu Zhou","isHighlighted":false,"isCorresponding":true,"isCoAuthor":false},{"name":"Xiangyu Zhang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Xiang Chen","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Terry Zhuo","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"David Lo","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Taolue Chen","isHighlighted":false,"isCorresponding":true,"isCoAuthor":false}],"year":2025,"month":"5","type":"journal","status":"published","tags":["SCI-Q1","CCF-A"],"keywords":[],"researchArea":"machine-learning","journal":"ACM Transactions on Software Engineering and Methodology","conference":"","doi":"10.1145/3728639","url":"https://doi.org/10.1145/3728639","code":"https://github.com/NTDXYG/DeCE","abstract":"$e","description":"A general and effective loss function DeCE (Deceptive Cross-Entropy) to defend Code Language Models against backdoor attacks, preventing overfitting to backdoor triggers.","selected":true,"bibtex":"$f"},{"id":"10634302","title":"Chain-of-Thought in Neural Code Generation: From and for Lightweight Language Models","abbr":"TSE'24","authors":[{"name":"Guang Yang","isHighlighted":true,"isCorresponding":false,"isCoAuthor":false},{"name":"Yu Zhou","isHighlighted":false,"isCorresponding":true,"isCoAuthor":false},{"name":"Xiang Chen","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Xiangyu Zhang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Terry Yue Zhuo","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Taolue Chen","isHighlighted":false,"isCorresponding":true,"isCoAuthor":false}],"year":2024,"month":"12","type":"journal","status":"published","tags":["SCI-Q1","CCF-A"],"keywords":["Codes;Cotton;Task analysis;Computational modeling;Benchmark testing;Training;Software engineering;Code generation;chain-of-thought;large language model;lightweight language model;program language processing"],"researchArea":"signal-processing","journal":"IEEE Transactions on Software Engineering","conference":"","volume":"50","issue":"9","pages":"2437-2457","doi":"10.1109/TSE.2024.3440503","code":"https://github.com/NTDXYG/COTTON","abstract":"$10","description":"A novel approach COTTON to automatically generate CoTs for code generation, achieving significant improvement in performance compared to the state-of-the-art baselines.","selected":true,"bibtex":"$11"},{"id":"yang2024important","title":"How important are good method names in neural code generation? a model robustness perspective","abbr":"TOSEM'24","authors":[{"name":"Guang Yang","isHighlighted":true,"isCorresponding":false,"isCoAuthor":false},{"name":"Yu Zhou","isHighlighted":false,"isCorresponding":true,"isCoAuthor":false},{"name":"Wenhua Yang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Tao Yue","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Xiang Chen","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Taolue Chen","isHighlighted":false,"isCorresponding":true,"isCoAuthor":false}],"year":2024,"month":"3","type":"journal","status":"published","tags":["SCI-Q1","CCF-A"],"keywords":[],"researchArea":"neural-networks","journal":"ACM Transactions on Software Engineering and Methodology","conference":"","volume":"33","issue":"3","pages":"1--35","doi":"10.1145/3630010","code":"https://github.com/NTDXYG/RADAR","abstract":"$12","description":"A novel approach RADAR to enhance the performance of PCGMs from a model robustness perspective.","selected":true,"bibtex":"$13"}],"title":"Selected Publications"}],["$","$L14","news",{"items":[{"date":"2025-12","content":"One paper has been accepted by IPM!"},{"date":"2025-11","content":"Started working as Postdoc at Zhejiang University."},{"date":"2025-10","content":"Completed and received my doctoral degree üéâ"},{"date":"2025-09","content":"Three papers have been accepted by ASE 2025!"},{"date":"2025-05","content":"One paper has been accepted by ACL Main!"},{"date":"2025-05","content":"One paper has been accepted by TSE!"},{"date":"2025-05","content":"Two papers have been accepted by TOSEM!"}],"title":"News"}]],false,false,false]}]]}]]}]}],["$","$L15",null,{"children":"$L16"}],null,["$","$L17",null,{"children":["$L18","$L19",["$","$L1a",null,{"promise":"$@1b"}]]}]]}],{},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","dMtUJr64VW1lrrgHyyXxL",{"children":[["$","$L1c",null,{"children":"$L1d"}],null]}],null]}],false]],"m":"$undefined","G":["$1e","$undefined"],"s":false,"S":true}
1f:"$Sreact.suspense"
20:I[4911,[],"AsyncMetadata"]
16:["$","$1f",null,{"fallback":null,"children":["$","$L20",null,{"promise":"$@21"}]}]
19:null
1d:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
18:null
21:{"metadata":[["$","title","0",{"children":"Guang Yang"}],["$","meta","1",{"name":"description","content":"Postdoctoral Researcher at Zhejiang University."}],["$","meta","2",{"name":"author","content":"Guang Yang"}],["$","meta","3",{"name":"keywords","content":"Guang Yang,PhD,Research,Zhejiang University"}],["$","meta","4",{"name":"creator","content":"Guang Yang"}],["$","meta","5",{"name":"publisher","content":"Guang Yang"}],["$","meta","6",{"property":"og:title","content":"Guang Yang"}],["$","meta","7",{"property":"og:description","content":"Postdoctoral Researcher at Zhejiang University."}],["$","meta","8",{"property":"og:site_name","content":"Guang Yang's Academic Website"}],["$","meta","9",{"property":"og:locale","content":"en_US"}],["$","meta","10",{"property":"og:type","content":"website"}],["$","meta","11",{"name":"twitter:card","content":"summary"}],["$","meta","12",{"name":"twitter:title","content":"Guang Yang"}],["$","meta","13",{"name":"twitter:description","content":"Postdoctoral Researcher at Zhejiang University."}],["$","link","14",{"rel":"icon","href":"/favicon.png"}]],"error":null,"digest":"$undefined"}
1b:{"metadata":"$21:metadata","error":null,"digest":"$undefined"}
